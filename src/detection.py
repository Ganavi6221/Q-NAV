import cv2
import numpy as np
from ultralytics import YOLO
import torch
"""Detects obstacles using YOLO AI model"""
class DebrisDetector:
    """Detects space debris/obstacles"""
    
    def __init__(self):
        print("üöÄ Starting Q-Nav Detector...")
        
        # Load YOLO AI model
        print("üì• Loading AI model (first time downloads ~6MB)...")
        self.model = YOLO('yolov8n.pt')
        
        # Check GPU/CPU
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"‚úì Using: {self.device}")
        
        # Statistics
        self.total_detections = 0
        self.total_frames = 0
        
        print("‚úì Ready!\n")
    
    def detect(self, frame):
        """
        Detect objects in frame
        
        Returns:
            detections: List of objects found
            annotated: Frame with boxes drawn
        """
        # Run AI detection
        results = self.model.predict(frame, conf=0.3, verbose=False)
        
        # Extract results
        detections = []
        for result in results:
            boxes = result.boxes
            for box in boxes:
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                confidence = box.conf[0].cpu().item()
                class_id = int(box.cls[0].cpu().item())
                class_name = self.model.names[class_id]
                
                detections.append({
                    'bbox': [int(x1), int(y1), int(x2), int(y2)],
                    'confidence': confidence,
                    'class': class_name
                })
        
        # Get annotated frame
        annotated = results[0].plot()
        
        # Update stats
        self.total_detections += len(detections)
        self.total_frames += 1
        
        return detections, annotated
    
    def calculate_risk(self, detections, frame_shape):
        if not detections:
            return 'SAFE', 0
        
        height, width = frame_shape[:2]
        center_x, center_y = width // 2, height // 2
        max_risk = 0
        
        for det in detections:
            x1, y1, x2, y2 = det['bbox']
            
            # 1. Size calculation (Percentage of screen occupied)
            size = ((x2 - x1) * (y2 - y1)) / (width * height)
            
            # NEW LOGIC: Size is weighted heavily. 
            # If size is 0.3 (30% of screen), score becomes 90.
            size_score = (size * 100) * 3 
            
            # 2. Proximity calculation (Distance from center)
            obj_x = (x1 + x2) / 2
            obj_y = (y1 + y2) / 2
            distance = np.sqrt((obj_x - center_x)**2 + (obj_y - center_y)**2)
            max_dist = np.sqrt(center_x**2 + center_y**2)
            
            # NEW LOGIC: Flattened Proximity
            # If it's in the inner 80% of the screen, it's a major threat.
            if distance < (max_dist * 0.8):
                proximity_score = 40 
            else:
                # Even on the edge, it's a threat, just slightly less immediate.
                proximity_score = 20 
            
            # Total risk calculation
            risk = size_score + proximity_score
            
            # Cap the risk at 100
            risk = min(risk, 100)
            max_risk = max(max_risk, risk)
        
        # Classification thresholds
        if max_risk >= 75:
            return 'HIGH', int(max_risk)
        elif max_risk >= 45:
            return 'MEDIUM', int(max_risk)
        elif max_risk >= 15:
            return 'LOW', int(max_risk)
        else:
            return 'SAFE', int(max_risk)
    
    def run_webcam(self):
        """Run detection on webcam"""
        print("üìπ Opening webcam...")
        print("Press 'q' to quit\n")
        
        cap = cv2.VideoCapture(0)
        
        if not cap.isOpened():
            print("‚ùå Cannot access webcam!")
            return
        
        print("‚úì Webcam active!\n")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # Detect
            detections, annotated = self.detect(frame)
            
            # Calculate risk
            risk_level, risk_score = self.calculate_risk(detections, frame.shape)
            
            # Color based on risk
            colors = {
                'SAFE': (0, 255, 0),
                'LOW': (0, 255, 255),
                'MEDIUM': (0, 165, 255),
                'HIGH': (0, 0, 255)
            }
            color = colors[risk_level]
            
            # Add text to frame
            cv2.putText(annotated, f"RISK: {risk_level}", 
                       (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)
            cv2.putText(annotated, f"Score: {risk_score}/100", 
                       (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
            cv2.putText(annotated, f"Objects: {len(detections)}", 
                       (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)
            
            # Show
            cv2.imshow('Q-Nav Detection', annotated)
            
            # Print
            if detections:
                print(f"Frame {self.total_frames}: {len(detections)} objects | Risk: {risk_level} ({risk_score})")
            
            # Quit
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        # Cleanup
        cap.release()
        cv2.destroyAllWindows()
        
        # Final stats
        print(f"\n{'='*50}")
        print("DETECTION COMPLETE")
        print(f"{'='*50}")
        print(f"Frames processed: {self.total_frames}")
        print(f"Total detections: {self.total_detections}")
        print(f"Average per frame: {self.total_detections/max(self.total_frames,1):.2f}")
        print(f"{'='*50}\n")


# Run the detector
if __name__ == "__main__":
    print("\n" + "="*50)
    print("üöÄ Q-NAV OBJECT DETECTION")
    print("="*50 + "\n")
    
    detector = DebrisDetector()
    detector.run_webcam()
    
    print("‚úì Done! üéâ\n")